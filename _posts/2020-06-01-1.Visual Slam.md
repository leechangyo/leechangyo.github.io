---
layout: post
title: 1. introduction to Visual SLAM
category: Visual SLAM
tag: Visual SLAM
---

# Introduction

<a href="https://postimg.cc/ykrchJzg"><img src="https://i.postimg.cc/kg7sm81c/Capture.jpg" width="500px" title="source: imgur.com" /><a>

- Visual Slam은 모바일 로봇 혹은 Mobility 능력을 갖춘 기계 시스템이 Lidar, Ladar, Camera, Ultra sonic 등과 같은 센서들을 이용하여서 물체 인식 및 Robot Localization(현지화), Building a Map 등을 이루게 만드는 기술이다.

- 특히 모바일 로봇틱스에서 많이 이용이 되는데, 모바일 로보틱스가 자율 주행을 하기 위해서는 아래와 같은 2개가 중요하다.
  - Localization
  - Mapping

# Simultaneous Localization and Mapping
- Visual Localization
  - 로봇에 장착된 센서만 이용(외부 장치 X)
  - GPS가 잘 작동하지 않는 환경

<a href="https://postimg.cc/bsqy38hQ"><img src="https://i.postimg.cc/8P67kPXn/Capture.png" width="500px" title="source: imgur.com" /><a>

- Mapping
  - 사전에 주변 환경이 만들어지지 않은 상태에서 주변환경(mapping and Building a Map)
  - 경로 계획에 대한 정보를 제공


<a href="https://postimg.cc/TLY8n2mw"><img src="https://i.postimg.cc/FR0957Hj/Capture.jpg" width="500px" title="source: imgur.com" /><a>

# Various Localization methods
- 가이드 레일, QR코드 GPS 센서
   - 실제로는 가이드 레일, QR 코드를 놓을 수 없는 경우가 많음
   - GPS 전파가 잘 닿지 않는 곳이 있음(실내, 도심지역)
   - 신뢰할 수 있지만 범용적이지 못함
   - 환경적인 제약이 존재
- Wheel Encoder, 카메라, Lidar, Ladar, IMU센서
  - 환경에 대한 간접적인 물리량을 측정
  - 환경에 대해 추가적인 설치 없이 위치 추정 문제 해결
  - 환경적인 제약이 있음
- Visual Slam
  - 카메라 센서를 주로 이용한 위치 추정 및 지도 작성 방법
- 카메라의 동작 방식에 따른 분류
  - 단안 카메라, 양안 카메라, 깊이 카메라

# 단안 카메라(Monocular Camera)
- 한개의 카메라를 움직여 물체까지 거리 추정 (Frame 별로 depending on Time)
- 깊이 추정 알고리즘(PnP, 3D-2D, Fundemantal Matrix, Essential Matrix)를 이용하여 각 픽셀의 시차(dispartiy)를 계산

<a href="https://postimg.cc/grpP361g"><img src="https://i.postimg.cc/pVhXbfCM/Capture.jpg" width="500px" title="source: imgur.com" /><a>

- 영상에서 Feature point를 추출하고 영상간의 Feature point 매칭을 통해 3차원 포인트를 계산(추정 알고리즘)

- 장점
  - 다른 방법들에 비해 간단
  - 계산량이 적고 실시간에 적합
- 단점
  - Dispartiy는 계산할 수 있지만 실제적인 Depth는 알 수 없음
    - Baseline 부재(RGB-D카메라에는 두개의 단안 카메라로 이루어져있어 기본적인 Baseline이 이있어 Feature Point를 이용한 더 정확한 3D point를 생성할 수 있다.)
  - 정확한 Scale 정보를 알 수 없음.

# 양안 카메라(Stereo Camera)
- 거리가 고정된 두 개의 단안 카메라를 이용하여 물체까지 거리 측정

<a href="https://postimg.cc/sB3ppm9V"><img src="https://i.postimg.cc/Ls1NF0JZ/Capture.jpg" width="500px" title="source: imgur.com" /><a>

<a href="https://postimg.cc/q6Khf6Xb"><img src="https://i.postimg.cc/1XCpqpgQ/Capture.jpg" width="500px" title="source: imgur.com" /><a>

- BaseLine: 두카메라 사이에 고정된 거리
  - 베이스 라인이 멀 수록 먼 거리를 측정 가능
  - 깊이 추정 알고리즘을 이용하여 3D point 구현 및 맵핑 가능
- 장점
  - 단안 카메라 경우 보다 정확한 위치 추정 능력
  - Dense한 맵 생성 가능
- 단점
  - 스테레오 매칭 알고리즘의 계산이 복잡
  - 조명 변화에 취약

# 깊이 카메라(RGB-D Camera)
- 적외선(IR) 구조광 방식 또는 레이저 광선의 비행 시간을 측정해 깊이를 예측
- 현재 일반적으로 사용되는 깊이 카메라
  - Kinect V1, Kinect V2
  - Xition Pro Live
  - Intel RealSense
  - Google Tango

<a href="https://postimg.cc/Yj7hj0RH"><img src="https://i.postimg.cc/sfQS6ZZv/download.jpg" width="500px" title="source: imgur.com" /><a>

- 장점
  - 비교적 정확한 깊이 값 예측이 가능
  - Dense한 맵 생성 가능
- 단점
  - 좁은 측정 범위
  - 작은 시야각
  - 반사, 투과성 재질의 물체 깊이 측정 불가
  - 주로 실내 으용에서 사용됨.

# Lidar(센서)
- 레이저 광선의 비행시간을 측정해 깊이를 예측
- 측정 가능 거리 및 공간 분해능이 높음

<a href="https://postimg.cc/87Sy0hBY"><img src="https://i.postimg.cc/4xKrnPKX/Capture.jpg" width="500px" title="source: imgur.com" /><a>

- 종류
  - 2D lidar/ 3D lidar
  - Spinning/Solid-State
- 주요 회사
  - Velodyne
  - Robosense
  - Ouster
  - SOSlab

<a href="https://postimg.cc/DJXLhN7P"><img src="https://i.postimg.cc/76BV3vcd/Capture.jpg" width="500px" title="source: imgur.com" /><a>

# 전통적인 Visual SLAM 프레임 워크

<a href="https://postimg.cc/HjXd630C"><img src="https://i.postimg.cc/ZYDnKMC0/Capture.jpg" width="500px" title="source: imgur.com" /><a>

- Sensor Input(Lidar, Camera)
  - Depth 이미지나 RGB이미지를 이용하여, intensity나 feature based extraction feature 포인트의 기술을 사용하여, 추적알고리즘을 통해 Visual odometery 구함
- Visual odomtery
- Backend Optimization
  - Bundle adjustment(BA)를 사용하여서 Localization을 업데이트 한다.
  - Graph based slam Optimization
- Loop Clousure detection
- Mapping

# Visual odometery
- Fronted 단계
- 인접한 이미지 사이의 카메라 움직임을 통하여 Camera pose 구함
- 카메라와 3차원 공간 점 사이의 기하학적 관계(multi-Geometry)를 이용
  - Feature Point(2D)를 3D 포인터로 생성
- Drift Error
  - Visual odometry만 이용하여 궤적을 추정하면 에러가 누적도미
- 해결책
  - Bacekend Optimization과 Loop Closure Detection 필요

  <a href="https://postimg.cc/yDMzhZJN"><img src="https://i.postimg.cc/DzZyTQn1/Capture.jpg" width="500px" title="source: imgur.com" /><a>

# Backend Optimization
- Sensor noise
  - 정밀한 센서라도 노이즈는 있기 마련
  - 저렴한 센서는 측정(Measurement) 오류가 큼
  - 일부 센서는 자기장과 온도에 영향을 받음
- Backend Optimization
  - 노이즈가 많은 데이터로부터 전체 시스템의 상태를 추정하는 방법(state estimation)
  - Fronted에서 발생한 Drift 에러를 제거
- Fronted에서는 backend에 최적화 할 데이터와 데이터의 초기 값을 제공
- Backend 최적화 종류
  - 필터 기반(Kalman filter, Particle Filter)
  - 비선형최적화 기반
    - Bundle Adjustment : 카메라 포즈와 3차원 포인트 재조정
    - Pose graph optimization 맵포인트를 고려하면 계산량이 커지므로 pose만 고려하는 방법

# Loop Closure Detection

<a href="https://postimg.cc/bdCWHtWj"><img src="https://i.postimg.cc/vHbyy7vD/Capture.jpg" width="500px" title="source: imgur.com" /><a>

- 현재 위치가 이전에 방문한 곳인지를 판단
- QR 코드 활용
  - 환경적인 제약이 존재
- 카메라 영상을 활용
  - 이미지간의 유사성을 판단(BoW(Bag of words))
  - Backend에서는 루프 폐쇄에 대한 정보를 받아서 위치 추정과 지도 작성에 반영
  - Drift 에러를 제거하고 전역적으로 일관된 맵으 생성

# Mapping

<a href="https://postimg.cc/dhMW4m9g"><img src="https://i.postimg.cc/52yZ9sQ9/Capture.jpg" width="500px" title="source: imgur.com" /><a>

- 환경 맵을 만드는 과정(Building a MAP)
- 응용프로그램에 따라 다르게 구현
  - 무인 청소 로봇
    - 2차원 지도로 충분
  - 자율주행 드론
    - 6DOF 이므로 3차원 지도가 필요
- Map Representation
  - Pointcloud
  - Voxel(volume matrix)
  - Surfel
  - Occupancy grid map
- 맵 표현 밀도에 따른 종류
  - Sparse, Dense, Semi-dense Map

# Modern State of the Art System
- Sparse SLAM
  - only use a small selected subset of the pixels(features) from a monocular color camera
  - Fast and Real time on CPU but it produces a sparse map(point clouds)
    - point clouds는 sparse information이다.
  - Landmark-based or feature-based representations

- ORB-SLAM
  - one of the SOTA frameworks in the sparse SLAM category
  - Complete SLAM system for monocular camera
  - Real-time on standard CPUs in a wide variety of environment.
    - small hand-held indoors
    - drones flying in industrial environments
    - cars driving around a city

<a href="https://postimg.cc/LhLgjtnJ"><img src="https://i.postimg.cc/HWP0D3m9/Capture.jpg" width="500px" title="source: imgur.com" /><a>

- Dense SLAM
  - using RGB-D camera
  - Use most of all the pixels in each received frame
  - or use depth images from a depth camera
  - it produces a dense map but GPU acceleration is necessary for the real time operation
  - Volumetric model or surfel-based representation

- InfiniTam
  - one of the SOTA frameworks in the Dense SLAM category
  - Multi-platform frameworks for real-time, Large-Scale Depth fusion and tracking
  - Densely Reconstructed 3D scenes

<a href="https://postimg.cc/SJQ8qXxj"><img src="https://i.postimg.cc/GhGjFG0P/Capture.jpg" width="500px" title="source: imgur.com" /><a>

- Direct Method(semi-Dense SLAM)
  - make use of pixel intensities directly
    - intensity 차이를 통해 Mapping
      - Warping을 통해 시점을 갖다 붙인다.(가장 작도록하여서 update)
  - Enable using all information in the image
  - it produces a semi-dense map
  - Higher accuracy and robustness in particular even in environments with little keypoints
- LSD SLAM
  - Highly cited SLAM framework in the direct method SLAM category
  - Large-scale, consistent maps of the environment
  - Accurate pose estimation based on direct image alignment.

<a href="https://postimg.cc/D8t26DHF"><img src="https://i.postimg.cc/9QfrmHB4/Capture.jpg" width="500px" title="source: imgur.com" /><a>

- Lidar SLAM
  - Make use of the Lidar sensor input for the localization and mapping
  - Autonomous driving purpose-oriented in outdoor environment
    - Lidar odometery maaping

- LOAM
  - One of the SOTA frameworks in the lidar SLAM category
  - Very low drift error using the edge and planar features
  - Low computation complexity
- 두 SLAM 기술을 통틀어 VLOAM이라고도 불림

<a href="https://postimg.cc/2VBY1G6t"><img src="https://i.postimg.cc/TYt3HHXT/Capture.jpg" width="500px" title="source: imgur.com" /><a>

# SLAM 문제의 수학적 표현
- Motion Model
  - Control input such as Velocity, IMU
  - 위와 같은 Velocity가 input으로 들어오고 hardware를 통해 출력이 될떄 로봇 위치가 어떻게 변하는지 표현 하는 것
  - Such as Wheel odometer encoded from wheel odometer encoder and predict a robot pose in an environment.
  - Velocity값을 이용하여 robot statement(x,y,z)값을 구하는것

<a href="https://postimg.cc/yJxvNQ6g"><img src="https://i.postimg.cc/N07VpSW4/Capture.jpg" width="500px" title="source: imgur.com" /><a>

- Sensor Model
  - 랜드마크가 로봇에서 어떻게 관찰되는지 표현
  - such as visual odometer from Tracking algorithm by Camera sensor.
  - Landmark를 통해 로봇 statement(x,y,z)를 구하는 것.

<a href="https://postimg.cc/ygSjmDZ7"><img src="https://i.postimg.cc/W35yPrpq/Capture.jpg" width="500px" title="source: imgur.com" /><a>

# Motion Model
- 로봇이 현재 위치에서 컨트롤 입력(e.g velocity) 받았을때 새로운 로봇 위치 예측
- Motion model 수학적 정의
  - x_f = f(x_k-1, u_k-1, w_k)
  - f() : Motion Model을 나타내는 함수
  - u_k : 모션 센서 및 컨트롤 입력 받은 값
  - w_k : Motion model에 대한 노이즈
- Motion Model로 부터 구해지는 x,y,z 값은 Kinematic formular를 통해서 구해진다.

<a href="https://postimg.cc/NyXbTyTB"><img src="https://i.postimg.cc/YSnP5YCG/Capture.jpg" width="500px" title="source: imgur.com" /><a>

- Example
 - 평면에서 움직이는 청소 로봇의 경우

<a href="https://postimg.cc/qgww8Hth"><img src="https://i.postimg.cc/CLT2pFSN/Capture.jpg" width="500px" title="source: imgur.com" /><a>

# Sensor Model
- 로봇이 위치에서 어떤 랜드마크(extracted feature point)를 볼때 관측 데이터(x,y,z of extracted feature point)가 생성되는 것을 표현
- Sensor Model의 수학적 정의
  - z_kj = h(y_j, x_k, v_k, j)
  - h() : Sensor Model을 나타내는 함수
  - y_j : 랜드 마크
  - x_k : 현재 로봇 위치
  - Z_kj : 랜드마크의 관찰 값(x,y,z of extracted feature point)
  - v_kj : Sensor model에 대한 노이즈
- Example
  - 평면에 움직이는 청소 로봇의 경우

<a href="https://postimg.cc/WFnG604L"><img src="https://i.postimg.cc/J0wp8qVn/Capture.jpg" width="500px" title="source: imgur.com" /><a>

# SLAM의 상태 추정 문제(State estimation)
- 모션 모델과 센서 모델 필요
  - x_f = f(x_k-1, u_k-1, w_k)
  - z_kj = h(y_j, x_k, v_k, j)
- 선형인가 비선형인가?
- 초기 SLAM 문제는 Extended Kalman Filter를 이용
  - Talyor expantion으로 선형화 한다(근사화)
- EFK SLAM의 단점
  - 선형화 과정에서의 오차
- Particle Filter, 비선형 최적화 방법을 사용하기 시작
- Graph 기반의 SLAM 방법이 주류를 이룸
  - Large Scale에 적합

# Reference
SLAM KR
视觉SLAM书
