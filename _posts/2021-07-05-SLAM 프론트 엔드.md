---
layout: post
title: SLAM 프론트 엔드
category: SLAM
tag: SLAM
---

### Camera

Feature Extraction(indirect, direct method) -> Pose Estimation(2D-2D(Mono), 2D-3D(BA), 3D-3D(ICP)) -> triangulation

indrect : kind of ORB extractor
direct : kind of Optical flow

Pose estimation : Descriptor matching(to find matched point between frames(KD-TREE FLANN)) -> find Essential matrix, fundemantial matrix with Epipolar constrain) -> SVD on Essential Matrix find Pose || further more  -> triangulation with essentail matrix and camera instrict(generating 3D Mappoints correspoinding frames) -> reprejection it to cur image frame to do least square(BA) to find pose or with KD-TREE FLANN find matched point to do ICP  

### Lidar

Feature Extraction(Curvature) - > pose estimation(NDT, ICP)

curvature : take K Pointcloud to making curvature(feature point) which creating it meaningful

pose estimation : now we have meaningful feature points generated from pointcloud using those feature point to do matching 3d points and pose estimation.(ICP,NDT)


### where it used?
Save Mappoints and keyframe and pose with unique index number(case, they qualify some condition such as 1000 Mappoints in keyframe something like that)in database and transport it to local mapping and full mapping, it is used in backend to construct the map.

### Summary
purpose of this is generating meaningful information from each frame for slam. and used it in backend.
