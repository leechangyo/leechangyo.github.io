I"ã<h1 id="modifications-for-cartpole">Modifications for CartPole</h1>

<ul>
  <li>Can we use the RBF Network + Q learning script with CartPole?</li>
  <li>Yes But with some modifications</li>
</ul>

<h2 id="sgdregressor">SGDRegressor</h2>
<ul>
  <li>we are going to build our own</li>
  <li>Practice building a linear gradient descent model</li>
  <li>We‚Äôll use the sampe API as scikit learn‚Äôs SGDRegressor</li>
  <li>Can‚Äôt use Optimistic initial value</li>
</ul>

<h2 id="rbf-example">RBF Example</h2>

<ul>
  <li>for mountain car, we sampled from the state space to get exemplars</li>
  <li>mountain car state space is bounded in a small region</li>
  <li>Cartpole state space is not</li>
  <li>Unfortunately the sample() method samples uniformly from all possible values, not proportional to how likely they are</li>
  <li>therefore, these would be poor exemplars</li>
  <li>instead, just ‚Äúguess‚Äù a plausible range( or callect data to find it)</li>
</ul>

<p>Reference:</p>

<p><a href="https://www.udemy.com/course/artificial-intelligence-reinforcement-learning-in-python/">Artificial Intelligence Reinforcement Learning</a></p>

<p><a href="https://www.udemy.com/deep-reinforcement-learning-in-python/">Advance AI : Deep-Reinforcement Learning</a></p>

<p><a href="https://www.udemy.com/cutting-edge-artificial-intelligence/learn/lecture/14650508#overview">Cutting-Edge Deep-Reinforcement Learning</a></p>
:ET