I"«%<h1 id="nonstationary-bandits">Nonstationary Bandits</h1>
<ul>
  <li>there equations will show up again and again</li>
  <li>what is stationary?</li>
  <li>A stationary process is one whose statistics donâ€™t change over rime(e.g mean)</li>
  <li>weak-sense stationary: mean(1st order statistic) and autocovariance(2nd order statistic) donâ€™t change overtime
    <ul>
      <li>if donâ€™t know covariance letâ€™s check it in <a href="https://ko.wikipedia.org/wiki/%EA%B3%B5%EB%B6%84%EC%82%B0">here</a></li>
    </ul>
  </li>
  <li>strong-sense stationary: entire PDF doesnâ€™t change over time</li>
  <li>SSS -&gt; WSS</li>
  <li>what if our bandits are not stationary? does it make sense to calculate the mean as we have been?
    <h2 id="mean-update-equation">Mean Update Equation</h2>
  </li>
  <li>from earlier:
<a href="https://postimg.cc/xXmKnx0z"><img src="https://i.postimg.cc/MpPt0NNd/51213.png" width="300px" title="source: imgur.com" /></a></li>
  <li>some rearranging for convenience:
<a href="https://postimg.cc/Z97Ygm1F"><img src="https://i.postimg.cc/501HXNgG/55151.png" width="400px" title="source: imgur.com" /></a></li>
  <li>Replace 1/t:
<a href="https://postimg.cc/hJJNDqX0"><img src="https://i.postimg.cc/W4SV7Njx/515.png" width="400px" title="source: imgur.com" /></a></li>
  <li>Alpha can be anything(even constant). looks kind of like gradient descent</li>
  <li>One adaptive learning rate used 1/t</li>
</ul>

<h2 id="low-pass-filter">Low pass filter</h2>
<ul>
  <li>should look familiar:
<a href="https://postimg.cc/068dnGsK"><img src="https://i.postimg.cc/Xv5HVx1L/51515.png" width="400px" title="source: imgur.com" /></a></li>
  <li>Low-pass filter studied in ML related to RNN(i will post ML too in future)</li>
  <li>Get rid of recurrence(å¤å‘):
 <a href="https://postimg.cc/NLrJ54fQ"><img src="https://i.postimg.cc/XNsT1HRB/521525.png" width="400px" title="source: imgur.com" /></a></li>
  <li>Q has exponentially decaying dependence on X</li>
  <li>More emphasis on recent value</li>
</ul>

<h2 id="convergence-criteria-for-q">Convergence Criteria for Q</h2>
<ul>
  <li>Q will converge if :
 <a href="https://postimg.cc/dLfGrMWX"><img src="https://i.postimg.cc/P5XKGT1t/51511312.png" width="400px" title="source: imgur.com" /></a></li>
  <li>think back to calculus 2(ë‘ë²ˆì¨°)</li>
  <li>constant alpha does not converge</li>
  <li>1/t does</li>
  <li>if problem is Nonstationary, we donâ€™t want Convergence(èåˆ)(equal weighting of all samples doesnâ€™t make sense) so we will see constant alpha used</li>
  <li>Does this converge?
  <a href="https://postimg.cc/WdJYJw7G"><img src="https://i.postimg.cc/VkKxp7rV/5123123.png" width="200px" title="source: imgur.com" /></a></li>
  <li>No. Sum of alphas is not infinity</li>
  <li>Does this convergence?
<a href="https://postimg.cc/sG71h8vF"><img src="https://i.postimg.cc/Y0yFJB7S/15121312413.png" width="200px" title="source: imgur.com" /></a></li>
  <li>Nonstationary systemì€ ëª¨ë¸ íŒŒë¼ë¯¸í„° Î˜ê°€ ì‹œê°„ì˜ ë³€í™”ì— ë”°ë¼ì„œ ìƒìˆ˜ê°€ ë³€í•œë‹¤. ê´‘ê³ ë¥¼ ì˜ˆì‹œë¥¼ ë“¤ë©´, ê´‘ê³ ì— ëŒ€í•œ ë°©ë¬¸ìì˜ ì„ í˜¸ë„ëŠ” ì œí’ˆì— ëŒ€í•œ ì†Œë¬¸, ì¦ì€ ê´‘ê³ , ë…¸ì¶œì— ë”°ë¥¸ ì—¬ëŸ¬ê°€ì§€ ì´ìœ ë¡œ ë³€í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì´ë‹¤. ì´ëŸ¬í•œ í™˜ê²½ì˜ MABë¬¸ì œë¥¼ Non-stationary ë¬¸ì œë¼ê³  í•œë‹¤. ì‹œê°„ì— íë¦„ì— ë”°ë¼ Î±+Î²ê°’ì´ ì¦ê°€í•¨ìœ¼ë¡œ Î˜ì— ëŒ€í•œ ì¶”ì •ì´ ì–´ë ¤ì›Œì§„ë‹¤.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># From the course: Bayesin Machine Learning in Python: A/B Testing
# https://deeplearningcourses.com/c/bayesian-machine-learning-in-python-ab-testing
# https://www.udemy.com/bayesian-machine-learning-in-python-ab-testing
</span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span><span class="p">,</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">builtins</span> <span class="kn">import</span> <span class="nb">range</span>
<span class="c1"># Note: you may need to update your version of future
# sudo pip install -U future
</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">bayesian_bandit</span> <span class="kn">import</span> <span class="n">Bandit</span>


<span class="k">def</span> <span class="nf">run_experiment</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span> <span class="n">p2</span><span class="p">,</span> <span class="n">p3</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
  <span class="n">bandits</span> <span class="o">=</span> <span class="p">[</span><span class="n">Bandit</span><span class="p">(</span><span class="n">p1</span><span class="p">),</span> <span class="n">Bandit</span><span class="p">(</span><span class="n">p2</span><span class="p">),</span> <span class="n">Bandit</span><span class="p">(</span><span class="n">p3</span><span class="p">)]</span>

  <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>

  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="c1"># thompson sampling
</span>    <span class="n">j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">([</span><span class="n">b</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">bandits</span><span class="p">])</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">bandits</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">pull</span><span class="p">()</span>
    <span class="n">bandits</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># for the plot
</span>    <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
  <span class="n">cumulative_average_ctr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

  <span class="c1"># plot moving average ctr
</span>  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cumulative_average_ctr</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">N</span><span class="p">)</span><span class="o">*</span><span class="n">p1</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">N</span><span class="p">)</span><span class="o">*</span><span class="n">p2</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">N</span><span class="p">)</span><span class="o">*</span><span class="n">p3</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xscale</span><span class="p">(</span><span class="s">'log'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="n">run_experiment</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mi">100000</span><span class="p">)</span>
</code></pre></div></div>
<p>Reference:</p>

<p><a href="https://www.udemy.com/course/artificial-intelligence-reinforcement-learning-in-python/">Artificial Intelligence Reinforcement Learning</a></p>

<p><a href="https://www.udemy.com/deep-reinforcement-learning-in-python/">Advance AI : Deep-Reinforcement Learning</a></p>

<p><a href="https://www.udemy.com/cutting-edge-artificial-intelligence/learn/lecture/14650508#overview">Cutting-Edge Deep-Reinforcement Learning</a></p>
:ET