I"g<h1 id="intro-to-dynamic-programming">intro to Dynamic Programming</h1>
<ul>
  <li>Solutions to MDPs</li>
  <li>Centrepiece of MDP: The bellman Equation
<a href="https://postimg.cc/5XWK8Hhk"><img src="https://i.postimg.cc/zGymZK05/4141313123.png" width="500px" title="source: imgur.com" /></a></li>
  <li>if we look carefully, this can be used to solve for V(s) Directly</li>
  <li>I S I equations, I S I unknowns(linear Problem)</li>
  <li>Many entries(进入(指行动)) will be 0, since transitions s -&gt; s’ are sparse</li>
  <li>Instead, we will use <strong>Iterative Policy evaluations</strong></li>
</ul>
:ET