I"3H<h1 id="approximation-methods">Approximation Methods</h1>
<ul>
  <li>Major Disadvantage of methods we’ve learned</li>
  <li>V - Need to estimate ISI values</li>
  <li>Q - Need to estimate ISI x IAI values</li>
  <li>ISI and IAI can be very large</li>
  <li>solution : Approximation</li>
  <li>Recall: neural networks are universal function approximator</li>
  <li>First, we do feature extraction: convert state s to <strong>feature vector x</strong>
<a href="https://postimg.cc/VSsNgQMT"><img src="https://i.postimg.cc/N0mrgQ0g/414141412312.png" width="100px" title="source: imgur.com" /><a></a></a></li>
  <li>we want a function, parameterized by theta, that accurately approximates V
<a href="https://postimg.cc/yJBDGp3q"><img src="https://i.postimg.cc/MGf1vhWG/123131.png" width="150px" title="source: imgur.com" /><a></a></a></li>
</ul>

<h2 id="1-linear-approximation">1. Linear Approximation</h2>
<ul>
  <li>Function approximation methods requires us to use models that are differentiable</li>
  <li>Can’t use something like decision tree or k-nearest neighbour</li>
  <li>in sequal(查询语言) to this section, we will use deep learning methods, which are differentiable</li>
  <li>Neural networks don’t require us to engineer features beforehand, but it can help</li>
  <li>FOr Approximation methods, we will need linear regression and gradient descent</li>
</ul>

<h2 id="2-section-outline">2. Section outline</h2>
<ul>
  <li>MC prediction</li>
  <li>TD(0) prediction</li>
  <li>SARSA</li>
</ul>

<h2 id="3-sanity明智-checking">3. Sanity(明智) Checking</h2>
<ul>
  <li>we can always sanity check our work by comparing to non-approximated versions</li>
  <li>we expect approximation to be close, but perhaps not exactly equal</li>
  <li>Obstacle we may encounter: our code is implemented perfectly, but our model is bad</li>
  <li>Linear models are not very expressive</li>
  <li>if we extract a poor set of features, model won’t learn value function well</li>
  <li>will need to put in manual work to do feature engineering</li>
</ul>

<h2 id="4-linear-model">4. Linear Model</h2>
<ul>
  <li>Supervised learning aka,<strong>Function Approximation</strong></li>
  <li>The function we are trying to approximate is V(s) or Q(s,a)</li>
  <li>Rewards are real numbers</li>
  <li>So returns, which are sums of rewards are real number</li>
  <li>2 Supervised learning techniques
    <ul>
      <li>Classification</li>
      <li>regression</li>
    </ul>
  </li>
  <li>we are doing regression</li>
</ul>

<h2 id="5-error">5. Error</h2>
<ul>
  <li>Supervised Learning methods have cost Functions</li>
  <li>Regression means squared error is the appropriate choice</li>
  <li>Squared difference between V and estimate of V
<a href="https://postimg.cc/m1G258rz"><img src="https://i.postimg.cc/Gt489fwQ/121231231231.png" width="300px" title="source: imgur.com" /><a></a></a></li>
  <li>Replace V with its definition</li>
  <li>But we don’t know this expected value
<a href="https://postimg.cc/s1rvggVY"><img src="https://i.postimg.cc/9X4T1DKn/124123124123.png" width="300px" title="source: imgur.com" /><a></a></a></li>
  <li>as we learned from MC(Monte Carlo), we can replace the expected value with its sample means
<a href="https://postimg.cc/0MrZ60G4"><img src="https://i.postimg.cc/DZPNMCS7/433.png" width="300px" title="source: imgur.com" /><a></a></a></li>
  <li>Alternatively, we can treat each G_(i,s) as a training sample</li>
  <li>And try to minimize all the <strong>individual squared differences</strong> simultaneously(just like linear regression)
<a href="https://postimg.cc/m1kDWtsC"><img src="https://i.postimg.cc/4ybht92L/41241312321.png" width="300px" title="source: imgur.com" /><a>
<a href="https://postimg.cc/XZKcpDyx"><img src="https://i.postimg.cc/vmkP2J8R/412313124123.png" width="200px" title="source: imgur.com" /><a></a></a></a></a></li>
</ul>

<h2 id="6-stochastic-gradient-descent">6. stochastic Gradient Descent</h2>
<ul>
  <li>we can now do stochastic(随机的) gradient decent</li>
  <li>Move in direction of gradient of error wrt only one sample at a time</li>
</ul>

<h3 id="gradient-descent-설명">Gradient Descent 설명</h3>
<ul>
  <li>Neural Network의 loss function의 현 weight의 기울기(gradient)를 구하고 Loss를 줄이는 방향으로 업데이트 나가는 방법
<a href="https://postimg.cc/XGVhJ5XG"><img src="https://i.postimg.cc/0QmqVdsf/124141312312.png" width="500px" title="source: imgur.com" /><a></a></a></li>
  <li>Loss function (ERROR) 는 현재 가중치(weight)에서 틀린 정도를 알려주는 함수이다.</li>
  <li>즉, 현재 네트워크의 weight에서 내가 가진 데이터를 집어 넣으면 에러가 생길 것이다. 거기에 미분을 하면 에러를 줄이는 방향을 알 수 있다.</li>
  <li>그 방향으로 정해진 Learning rate를 통해서 weight를 이동시킨다. 이것을 반복해서 학습하는 것이다.</li>
  <li><strong>즉 Gradient Descent는 현재 네트워크의 Weight에 어떤 데이터를 넣을 떄 에러값을 미분해서 에러의 방향(Gradient)을 알애체고 그 방향으로 정해진 Learning rate를 통해서 weight을 이동시킨다(Descent).</strong>
<a href="https://postimg.cc/kR47V4fs"><img src="https://i.postimg.cc/fy7yrSdG/141412412312312.png" width="500px" title="source: imgur.com" /><a></a></a></li>
  <li>Gradient Descent의 단점은 가진 데이터를 다 넣으면 전체 에러가 계산이 될 것이다.</li>
  <li>그렇기 때문에 최적값을 찾아 나가기 위해서 한칸 전진할 때마다 모든 데이터 셋을 넣어주어야 해야하기 때문에 학습이 굉장히 오래 걸리는 문제가 발생하게 된다.</li>
  <li>그럼 Gradient Descent 말고 더 빠른 Optimizer 는 없을까? 그것이 바로 <strong>stochastic Gradient Descent</strong> 이다.</li>
</ul>

<h3 id="stochastic-gradient-descent">Stochastic Gradient Descent</h3>
<ul>
  <li>Stochastic Gradient Descent(SGD)는 조금만 흝어보고(Mini Batch)빠르게 학습 하는 것이다.
<a href="https://postimg.cc/qhZ26tpM"><img src="https://i.postimg.cc/d3J6XdXd/41241231312312.png" width="500px" title="source: imgur.com" /><a></a></a></li>
  <li>최적값을 찾아 과정은 이와 같다
<a href="https://postimg.cc/D8YyVqBz"><img src="https://i.postimg.cc/vZG1Vhn5/111.png" width="500px" title="source: imgur.com" /><a></a></a></li>
  <li>GD의 경우 항상 전체 데이터 셋을 가지고 Learning rate로 최적의 값을 찾아가는 모습을 불 수 있다.</li>
  <li>SGD 같은 경우 Mini-batch 사이즈 만큼 조금씩 돌려서 최적의 값으로 찾아나간다.</li>
</ul>

<h2 id="7-gradient-descent">7. Gradient Descent</h2>
<p><a href="https://postimg.cc/Hrs5z4js"><img src="https://i.postimg.cc/bw1Tzmhb/4121312312312.png" width="200px" title="source: imgur.com" /><a></a></a></p>
<ul>
  <li>we would work for all models, not just linear models
<a href="https://postimg.cc/r0L516r7"><img src="https://i.postimg.cc/C1RJVSLM/222.png" width="300px" title="source: imgur.com" /><a></a></a></li>
</ul>

<h3 id="gradient-descent-for-linear-models">Gradient Descent for Linear Models</h3>
<p><a href="https://postimg.cc/B8JqHMvM"><img src="https://i.postimg.cc/CKqzy2pT/412312312312321312.png" width="300px" title="source: imgur.com" /><a></a></a></p>

<h2 id="8-relationship-to-montel-carlo">8. Relationship to Montel Carlo</h2>
<ul>
  <li>Recall when we did not parameterized V(s) - as if V(s) itself was a parameter
<a href="https://postimg.cc/H8YZt8MG"><img src="https://i.postimg.cc/XqFR4w7v/1241231312.png" width="500px" title="source: imgur.com" /><a></a></a></li>
  <li>this is the exact same equation we had before for Mote Carlo</li>
  <li>therefore, what we were doing was an instance of <strong>gradient descent</strong></li>
</ul>

<h2 id="9-feature-engineering">9. Feature Engineering</h2>
<ul>
  <li>Recall: neural networks can in some sense find good nonlinear transformations / features of the raw data</li>
  <li>since we only study linear methods in the past section, we need to find features manually</li>
  <li>Feature Engineering 머신러닝 알고리즘을 작동하기 위해 데이터에 대한 도메인 지식을 활용하여 특징(Feature)을 만들어 내는 것</li>
  <li>머신러닝 모델을 위한 데이터 테이블의 column(특징)을 생성하거나 선택하는 작업을 의미</li>
  <li>즉 모델의 성능을 높이기 위해 초기 주어진 데이터로부터 특징을 가공하고 생성하는 전체 과정</li>
  <li>Feature Engineering 모델 성능에 미치는 영향이 크기 때문에 머신러닝 응용에 있어서 굉장히 중요한 단계</li>
  <li>Feature Engineering 아래와 같은 단계에 구성되어 있다.
    <ol>
      <li>Project scoping(Define Problem)</li>
      <li>Data Collection</li>
      <li>EDA</li>
      <li>Data Preprocessing</li>
      <li><strong>Feature Engineering</strong></li>
      <li>Modeling</li>
      <li>Evaluation</li>
      <li>Project Delivery / Insights</li>
    </ol>
  </li>
  <li>Feature Eingeering은 모델에 입력하기 전 단계에 데이터의 특성을 잘 반영하고 성능을 높일 수 있도록 특징을 생성하고 가공하는 단계이다.</li>
  <li>Feature Engineering에 구성은 아래와 같다.</li>
</ul>

<h3 id="방법적인-측면">방법적인 측면</h3>

<ol>
  <li>Feature Selection(특징 선택)
    <ul>
      <li>특징 랭킹(Feature Ranking) 또는 특징 중요도 (Feature Importance)라고도 불린다.</li>
      <li>불류 모델 중 Decision Tree 같은 경우 트리의 상단에 있을 수록 중요도가 높으므로 이를 반영하여 특징 별로 중요도를 매긴다.</li>
      <li>회귀 모델의 경우 Forward Selection 과 Backward Elimination 같은 알고리즘을 통해 특징을 선택한다.</li>
    </ul>
  </li>
  <li>Dimension Reduction(차원 감소)
    <ul>
      <li>Dimension Reduction은 Feature extraction(특징 추출)이라는 말로도 불린다.</li>
      <li>차원 축소는 데이터의 압축이나 잡음을 제거하는 효과도 있지만, <strong>관측 데이터를 잘 설명할 수 있는 잠재 공간(Latent space)을 찾는 것이다.</strong></li>
      <li>가장 대표적인 알고리즘은 PCA(Principle Component Analysis)</li>
      <li>PCA는 각 Feature(변수)를 하나의 축으로 투영시켰을 때 분산이 가장 큰 축을 첫번째 주성분으로 선택하고 그다음 큰 축을 두번째 주성분으로 선택하고 데이터를 선형 변환하여 다차원을 축소하는 방법이다.
        <h3 id="domain분야-전문성-측면">Domain(분야) 전문성 측면</h3>
      </li>
    </ul>
  </li>
  <li>Feature Generation(특징 생성) or Feature Construction(특징 구축)
    <ul>
      <li>이 방법을 주로 Feature Engineering 이라고 말한다.</li>
      <li>초기에 주어진 데이터로 부터 모델링 성능을 높이는 새로운 특징을 만드는 과정이다.</li>
      <li>이때 데이터에 대한 Domain(분야) 전문성을 바탕으로 데이터를 합치거나 쪼개는 등을 거쳐 Feature을 만들게 된다.</li>
      <li>간단한 예로 시간 데이터를 AM/PM으로 나누는 것이다.</li>
      <li>이 작업은 한번 해서 끝나는 것이 아니라 끊임 없이 모델링 성능을 높이는 목적으로 반복해서 작업할 수 있는 부분이기 때문에 전문성과 경험에 따라 비용과 시간을 줄일 수 있는 부분이다.</li>
    </ul>
  </li>
</ol>

<h3 id="mapping-s---x">Mapping s -&gt; x</h3>
<ul>
  <li>states can be thought of as categorical variable
    <ul>
      <li>(0,0) -&gt; category 1</li>
      <li>(0,1) -&gt; category 2</li>
      <li>etc</li>
    </ul>
  </li>
  <li>how do we treat categorical variable? <strong>One-Hot encoding</strong></li>
  <li>what if we do one-hot encoding?
<a href="https://postimg.cc/VSv9RyDN"><img src="https://i.postimg.cc/0Ndt9PS7/4141231232132.png" width="100px" title="source: imgur.com" /><a></a></a></li>
  <li>s=(0,0) -&gt; x=[1,0,0,..]</li>
  <li>s=(0,1) -&gt; x=[0,1,0,..]</li>
  <li>D is the cardinality(基数) of S
    <ul>
      <li>집합의 cardinality는 집합의 원소의 개수를 말한다.</li>
      <li>두 집합 A,B가 cardinal number가 같다고 함은 일대일 대응 f: A–&gt; B가 존재하는 것이다.</li>
      <li>따라서 두 집합 A,B cardinal number가 같다면 원소의 개수가 같은것이다.</li>
    </ul>
  </li>
  <li>Problem with one-hot encoding: this requires the same number of parameters as measuring V(s) directly</li>
  <li>i.e. V is a dict with ISI keys and ISI values</li>
  <li>if we do one-hot encoding, each Component $θ_i$ actually represents V(s=i) itself
<a href="https://postimg.cc/ygFTJmLh"><img src="https://i.postimg.cc/ydGpbn9G/1412312412313.png" width="300px" title="source: imgur.com" /><a></a></a></li>
</ul>

<h3 id="one-hot-encoding">One-Hot Encoding</h3>
<ul>
  <li>one positive aspect to using one-hot encoding</li>
  <li>suppose our code is not working(our V isn’t accurate)</li>
  <li>we can have perfectly good code/no bugs, but still might not yield good results because feature are bad</li>
  <li>Change feature transformer to use one-hot encoding</li>
  <li>if it starts working, that confirm our features are bat(since it’s the same as a non-approximate method)</li>
</ul>

<h3 id="alternative-to-one-hot">Alternative to One-Hot</h3>
<ul>
  <li>in case of GridWorld, each(i,j) represents a position in 2-D space</li>
  <li>it’s more like 2 real numbers than a category</li>
  <li>Vector x can be (i,j) itself</li>
  <li>could scale it so mean = 0 and var = 1</li>
  <li>this x is the “raw data”</li>
  <li>problem
    <ul>
      <li>model is only linear</li>
      <li>for fixed j, V(i) is just a line
<a href="https://postimg.cc/SjZpjCHb"><img src="https://i.postimg.cc/CL0MP4N5/41312312.png" width="300px" title="source: imgur.com" /><a></a></a></li>
    </ul>
  </li>
</ul>

<h3 id="polynomials">Polynomials</h3>
<ul>
  <li>Recall from linear regression class: we can make new features by creating polynomials</li>
  <li>Recall from calculus: infinite taylor expansion can approximate any function</li>
  <li>Ex. second order terms
    <ul>
      <li>$x_1$^2</li>
      <li>$x_2$^2</li>
      <li>$x_1$$x_2$</li>
    </ul>
  </li>
  <li>don’t overfit</li>
</ul>

<h2 id="10-approximation-mc-prediction">10. Approximation MC Prediction</h2>
<ul>
  <li>Replace V(s) with linear model</li>
  <li>there are two main steps
    <ol>
      <li>Play game, get sequence of stats and returns</li>
      <li>Update V(s) as average of return
<a href="https://postimg.cc/xXxdVqS9"><img src="https://i.postimg.cc/hGgQx7yQ/412413131.png" width="300px" title="source: imgur.com" /><a></a></a></li>
    </ol>
  </li>
  <li>With Approximation
    <ol>
      <li>Play game, get sequence of stats and returns</li>
      <li>Update V(s) as average of return
<a href="https://postimg.cc/phxVDjfY"><img src="https://i.postimg.cc/1tVg1c4T/4131413.png" width="300px" title="source: imgur.com" /><a></a></a></li>
    </ol>
  </li>
</ul>

<blockquote>
  <p>Pseudocode</p>
  <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def mc_approx_prediction(π):
  θ = random
  for i = 1..N
    states_and_returns = play_game
    for s, g in states_and_returns:
      x = Φ(s)
      θ = θ + α(g-θ^T*x)x
</code></pre></div>  </div>
</blockquote>

<h2 id="11-approximation-td0">11. Approximation TD(0)</h2>
<ul>
  <li>apply approximation to TD(0) -&gt; but one caveat(警告)</li>
  <li>Main difference between MC and TD(0): instead of Using G, we use r+ɣV(s’)
<a href="https://postimg.cc/xJMwPjGv"><img src="https://i.postimg.cc/G25bdHH5/1232131.png" width="500px" title="source: imgur.com" /><a></a></a></li>
  <li>Problem
    <ul>
      <li>the target is not a real target, because it require a model prediction</li>
      <li>Gradient is not a true gradient, so we call it a <strong>“Semi-Gradient”</strong></li>
    </ul>
  </li>
  <li>Remember don’t need to calculate returns, use rewards directly</li>
</ul>

<h2 id="12-semi-gradient-sarsa">12. Semi-Gradient SARSA</h2>
<ul>
  <li>SARSA with approximation</li>
  <li>we will approximate Q</li>
  <li>More difficult than Approximating V, Since instead of approximating ISI value, we need to approximate ISI x IAI values</li>
  <li>Model Prediction appears in target again, so this is another instance of semi gradient
<a href="https://postimg.cc/47R90wcD"><img src="https://i.postimg.cc/wv7Q7Gjj/51321342.png" width="500px" title="source: imgur.com" /><a></a></a></li>
  <li>Features
    <ul>
      <li>Need to combine(s,a) -&gt; x</li>
      <li>Simple Idea: take our old encoding of s(r,c,r*c) and add one-hot encoding of action</li>
      <li>x = (r,c,r*c,U,D,L,R,1)</li>
      <li>r,c is the raw and column</li>
      <li>it well not approximate Q well but try to find it</li>
    </ul>
  </li>
  <li>Best Features
    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>x = [
 r &amp;&amp; U,
 c* &amp;&amp; U,
 r*r &amp;&amp; U,
 c*c &amp;&amp; U,
 r*c &amp;&amp; U,
 l &amp;&amp; U,
 r &amp;&amp; D,
]
</code></pre></div>    </div>
    <ul>
      <li>6 per action x 4actions + 1bias = 25 features</li>
      <li><a href="https://passi0n.tistory.com/86">tabular method</a> : 9states x 4actions = 36</li>
      <li>action value function을 Q-Table로 작성하여 푸는 방법을 Tabular Methods</li>
      <li>Tabular Methods를 state 나 action이 작을때만 적용 가능 하다고 한다.</li>
      <li>왜냐하면 각각의 state에 action마다 Q값을 넣어줘야 하기 때문이다. 그래서 실제 환경이나 실생활, 혹은 연속적인 환경에서는 적용을 할 수 없다.</li>
    </ul>
  </li>
  <li><strong>Similar to NLP: word2idx is a dict that maps each word to a unique index in x</strong></li>
  <li>SA2IDX(Semi-gradient SARSA) is a dict that maps(s,a) to a unique index in x</li>
</ul>

<h2 id="13-summary">13. Summary</h2>
<ul>
  <li>State Space can grow too large to feasibly enumerate</li>
  <li>Approximation methods allow us to compress number of parameters needed</li>
  <li>
    <h2 id="differentiable-models-are-a-good-fit-because-we-can-use-stochastic-gradient-decents">differentiable Models are a good fit, because we can use stochastic gradient decents</h2>
  </li>
</ul>
:ET