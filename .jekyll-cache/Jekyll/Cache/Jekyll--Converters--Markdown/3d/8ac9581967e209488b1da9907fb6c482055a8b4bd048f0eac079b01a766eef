I"-<h1 id="markov-decision-processes">Markov Decision Processes</h1>
<ul>
  <li>this section: formalize some RL concepts we already know about</li>
  <li>Agent, Environment, action, state, reward, episode</li>
  <li>Formal Framework: Markov Decision Processes(MDPs)</li>
</ul>

<h2 id="1-typical-game-by-solving-mdps-is-gridword">1. Typical Game by solving MDPs is GridWord</h2>
<p><a href="https://postimg.cc/VdS9ym01"><img src="https://i.postimg.cc/FspTLK9f/54123.png" width="500px" title="source: imgur.com" /></a></p>
<ul>
  <li>possible actions:</li>
  <li>up,down,left,right</li>
  <li>(1,1) -&gt; wall,can’t go here</li>
  <li>(0,3) -&gt; Terminal(+1 Reward)</li>
  <li>(1,3) -&gt; Terminal(-1 Reward)</li>
  <li>12 Positions(w x h = 3 x 4 = 12)</li>
  <li>11 states (where the robot is)</li>
  <li>4 actions</li>
</ul>

<h2 id="2-markov-property">2. Markov Property</h2>
<ul>
  <li>Given a sequence:
 <a href="https://postimg.cc/fJKVgPBZ"><img src="https://i.postimg.cc/2Spn3RWq/4121233.png" width="500px" title="source: imgur.com" /></a></li>
  <li>Generally, this can’t be simplified:
 <a href="https://postimg.cc/VdS9ym01"><img src="https://i.postimg.cc/FspTLK9f/54123.png" width="500px" title="source: imgur.com" /></a></li>
  <li>First-order Markov:
 <a href="https://postimg.cc/VdS9ym01"><img src="https://i.postimg.cc/FspTLK9f/54123.png" width="500px" title="source: imgur.com" /></a></li>
  <li>second-order Markov:
 <a href="https://postimg.cc/VdS9ym01"><img src="https://i.postimg.cc/FspTLK9f/54123.png" width="500px" title="source: imgur.com" /></a></li>
</ul>
:ET