I"e0<h1 id="multi-armed-bandit">Multi Armed Bandit</h1>
<p><a href="https://postimg.cc/9wdWmWHw"><img src="https://i.postimg.cc/Zng0LRfH/1412314123.png" width="700px" title="source: imgur.com" /></a></p>
<ul>
  <li>First saw in: bayesian Machine Learning(Probability Algorithm): A/B Testing (Ex. go to a Casino; choice between 3 slot machines)</li>
  <li>Each (for now) gives reward of 0 or 1</li>
  <li>win rate is unknown(Ex. Could be 0.1 0.3 0.5)</li>
  <li>Goal: Maximize our winnings</li>
  <li>Problem: can only discover best bandit by collecting data</li>
  <li>if we’re psychic, we could just play the bandit with highest win rate</li>
  <li>Balance explore(collectiong data) + exploit(playing “best-so-far” machines)</li>
</ul>

<h2 id="1traditional-ab-testing">1.Traditional A/B Testing</h2>
<script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<div align="center" style="margin: 1em 0;">
<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-5150894678574694" data-ad-slot="9221331439" data-ad-format="auto" data-full-width-responsive="true"></ins>
     </div>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

<ul>
  <li>Predetermine # of times we need to play/collect data in order to establish statistical significance</li>
  <li>. # of times needed is dependent on numerous things like the difference between win rates of each bandit(but if we know that, we wouldn’t be doing this test, weird traditional statistics ideas)</li>
  <li>important rule: Don’t stop our test early. Even if we set N=1000, but after 500 trials, we discover 90% win-rate vs 10% win rate. we still may not stop</li>
  <li>Much different from Human behavior</li>
  <li>suppose we’re playing in a real casino, we get 2/3 on one bandit, 0/3 on the other.</li>
  <li>we have a strong urge to play the first Bandit</li>
  <li>we know “ as a data scientist” that 3 is a small sample size</li>
  <li>as a gambler we do not “feel” that way</li>
  <li>we look at ways to systematically make explore-exploit trade-off(explain upcoming next)</li>
  <li>better than these 2 suboptimal solutions: A/B testing, human emotion</li>
</ul>

<h2 id="2-applications-of-explore-exploit">2. Applications of Explore-Exploit</h2>
<p><a href="https://postimg.cc/56crLZZy"><img src="https://i.postimg.cc/gkrPFpsV/41231241231214.png" width="700px" title="source: imgur.com" /></a></p>
<ul>
  <li>Already discussed in bayesian Machine Learning
    <ul>
      <li>if you don’t know let’s check it <a href="http://fastml.com/bayesian-machine-learning/">here</a></li>
    </ul>
  </li>
  <li>Lots of scary math! How does it apply in the “real world”?</li>
  <li>the casino example seems contrived(预谋的)</li>
  <li>The explore-exploit dilemma(and the subsequent Algorithm which are intended to “solve” it) are one of the most, if not the most “real world” concepts in Machine Learning</li>
  <li>Almost every business and online entrepreneur can make use of them</li>
</ul>

<h2 id="3-comparing-things">3. Comparing things</h2>
<p><a href="https://postimg.cc/qgC3WYg8"><img src="https://i.postimg.cc/RCgLJxBb/412312412312421.jpg" width="700px" title="source: imgur.com" /></a></p>
<ul>
  <li>Quantitatively comparing things applies to almost any business(E.g. we are samsung, selling note8)</li>
  <li>we have 2 ads we really Like</li>
  <li>which one is better? the one more likely to lead the user to purchase the phone(naturally)</li>
  <li>Can measure the <strong>click-through rate(CTR)</strong> of each ad ( E.g. 10 Clicks/1000 impressions = 1 % CTR)</li>
  <li>How to measure the CTR? Do an <strong>Experiment</strong></li>
  <li>Show the first ad to 1 million users and Show the second ad to 1 million users</li>
  <li>Calculate the CTRs and compare</li>
  <li>How do i know 1 million is the correct number?</li>
</ul>

<h2 id="4-the-nature-of-probability">4. The nature of Probability</h2>
<p><a href="https://postimg.cc/zL4HtSwz"><img src="https://i.postimg.cc/NMj80d5H/5141131241232.png" width="700px" title="source: imgur.com" /></a></p>
<ul>
  <li>We would need an infinite number of samples to get an absolutely precise estimate of the CTR</li>
  <li>as we collect more samples, the confidence interval shrinks</li>
  <li>therefore, the more samples we collect, the better</li>
  <li>but, if one advertisement is better, that means the other is <em>worse</em></li>
  <li>if i show the suboptimal(未达最佳标准的) ad 1 million times, i’ve wasted 1million impressions to get a suboptimal CTR</li>
  <li>my desire to show only the best advertisement(hence make more money) is fundamentally at odds with my desire to have an accurate CTR
    <ul>
      <li>which is needed to know which advertisement is “best” in the first place</li>
    </ul>
  </li>
</ul>

<h2 id="5-who-cares">5. Who cares?</h2>
<script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<div align="center" style="margin: 1em 0;">
<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-5150894678574694" data-ad-slot="9221331439" data-ad-format="auto" data-full-width-responsive="true"></ins>
     </div>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

<ul>
  <li>apple is not the only company selling things</li>
  <li>almost every modern business uses online advertising</li>
  <li>but we don’t have to be one, we can simply be someone who owns a website
    <ul>
      <li>Compare viewing time on old design vs new design</li>
      <li>is “Buy Now” button better at the top or bottom of sales pages?</li>
      <li>which “price ending” leads to the most conversions? ￦2000 vs ￦1999</li>
    </ul>
  </li>
  <li>these are all the same problem numerically</li>
  <li>Note: Click Through and conversion rate is the same thing to us, just a generic “success rate”</li>
</ul>

<h2 id="6-gaussian-vs-bernoulli">6. Gaussian vs Bernoulli</h2>
<p><a href="https://postimg.cc/NKPfx6md"><img src="https://i.postimg.cc/jjRwtv5Y/413141312413.png" width="700px" title="source: imgur.com" /></a></p>
<ul>
  <li>Bernoulli good for measuring success rates</li>
  <li>Gaussian for Continuous variables</li>
</ul>

<h2 id="7-epsilon-greedy">7. Epsilon-Greedy</h2>
<p><a href="https://postimg.cc/Q97yz3PF"><img src="https://i.postimg.cc/tTvGYRNN/41241414141141.png" width="700px" title="source: imgur.com" /></a></p>
<ul>
  <li>Solution to the explore-exploit dilemma</li>
  <li>Choose small number ε as Probability of exploration</li>
  <li>Typical values: 5%, 10%</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">p</span> <span class="o">=</span> <span class="n">random</span><span class="p">()</span>
<span class="k">if</span> <span class="n">p</span> <span class="o">&lt;</span> <span class="n">eps</span><span class="p">:</span>
  <span class="n">pull</span> <span class="n">random</span> <span class="n">arm</span>
<span class="k">else</span><span class="p">:</span>
  <span class="n">pull</span> <span class="n">current</span><span class="o">-</span><span class="n">best</span>  <span class="n">arm</span>
</code></pre></div></div>

<ul>
  <li>Eventually, we’ll discover which arm is the true best, since this allows us to update every arm’s estimate</li>
  <li>in the long run, allows us to explore each arm an infinite number of times</li>
  <li>Problem: we get to a point where we explore when we don’t need to</li>
  <li>For epsilon = 10%, we’ll continue to spend 10% of the time doing suboptimal things</li>
  <li>Could do A/B test at some Predetermined time, then set epsilon=0</li>
  <li>But we’ll learn better ways to adapt</li>
</ul>

<h2 id="8-estimating-bandit-rewards">8. Estimating Bandit Rewards</h2>
<p><a href="https://postimg.cc/7fqTbNqc"><img src="https://i.postimg.cc/fT972Hpw/4124141231241231.png" width="700px" title="source: imgur.com" /></a></p>
<ul>
  <li>Assuming bandit rewards are not just coin tosses.</li>
  <li>The best way to keep track of reward is General Method “Mean”</li>
  <li>Works for $ 1/0 $ too</li>
</ul>

<p>$P(k=1) $ $ = (#of1’s)/(#of1’s+#of0’s)$  = $ (#of1’s)/N $</p>

<ul>
  <li>P is Probability</li>
  <li>Need to keep Track of All X</li>
  <li>Can we be more efficient? YES!
<a href="https://postimg.cc/sQcKZgZC"><img src="https://i.postimg.cc/D0VNHWv0/4124141414141414.png" width="700px" title="source: imgur.com" /></a></li>
  <li>New mean can be calculated from old mean like that</li>
  <li>this “form” is very important to Reinforcement Learning</li>
</ul>

<h2 id="9-lets-recap-how-do-this-in-supervised-learningnaive-bayes-decision-trees-neural-networks">9. Let’s Recap how do this in supervised learning(Naive Bayes, Decision Trees, Neural Networks)</h2>
<script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<div align="center" style="margin: 1em 0;">
<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-5150894678574694" data-ad-slot="9221331439" data-ad-format="auto" data-full-width-responsive="true"></ins>
     </div>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Mymodel</span><span class="p">:</span>
  <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
    <span class="c1"># our job
</span>  <span class="k">def</span> <span class="nf">Predict</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="c1"># our job
</span></code></pre></div></div>
<ul>
  <li>For example boilerplate</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Xtrain</span><span class="p">,</span> <span class="n">Ytrain</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">Ytest</span>  <span class="o">=</span> <span class="n">get_data</span><span class="p">()</span> <span class="c1"># 1. Get data
</span><span class="n">model</span> <span class="o">=</span> <span class="n">Mymodel</span><span class="p">()</span> <span class="c1"># 2. Instantiate Model
</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span><span class="n">Ytrain</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">socre</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span><span class="n">Ytest</span><span class="p">)</span>
</code></pre></div></div>
<h2 id="10-designing-our-bandit-program">10. Designing our bandit Program</h2>
<ul>
  <li>Since this is not Supervised learning, there is still a pattern to be followed</li>
  <li>Reminder: A “casino Machine” is just an analogy for real-life applications
    <ul>
      <li>Serving advertisements you hope users will click on</li>
      <li>Testing different website design to see which keeps our users engaged longest</li>
    </ul>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MyAwesomeCasinoMachine</span><span class="p">:</span>
  <span class="k">def</span> <span class="nf">pull</span><span class="p">():</span>
    <span class="c1"># simulates drawing from the true distribution
</span>    <span class="c1"># which we wouldnt know in "real life"
</span><span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iterations</span><span class="p">):</span>
  <span class="c1"># pick casino machine to play based on Algorithm
</span>  <span class="c1"># update Algorithm parameters
# plot useful info (ave reward, best machine, etc)
</span></code></pre></div></div>
<p>Reference
<a href="https://www.udemy.com/cutting-edge-artificial-intelligence/learn/lecture/14650508#overview">Cutting-Edge Deep-Reinforcement Learning</a></p>
:ET