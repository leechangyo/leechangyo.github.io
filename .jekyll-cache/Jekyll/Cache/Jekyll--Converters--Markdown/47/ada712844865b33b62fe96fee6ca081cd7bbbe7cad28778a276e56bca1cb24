I"Õ<h2 id="what-is-reinforcement-learning">What is Reinforcement Learning?</h2>

<p><a href="https://postimg.cc/qNRLDkZb"><img src="https://i.postimg.cc/130jtX0Q/14512412123124123.png" width="700px" title="source: imgur.com" /></a></p>

<ul>
  <li>Humans/ AIs alike never sense the entire world/universe at once</li>
  <li>We have sensors which feed signals to our brain from the environment</li>
  <li>We don‚Äôt even know everything that‚Äôs going on in a room</li>
  <li>Thus the Sensors limit the amount of information we get</li>
  <li>The measurements we get from these sensors(e.g. sight, sound touch) make up a ‚Äústate‚Äù</li>
  <li>we‚Äôll only discuss finite state spaces</li>
  <li>state spaces with an infinite number of states are possible too</li>
</ul>

<p><a href="https://postimg.cc/y3jG9Lkk"><img src="https://i.postimg.cc/hhRRkwnb/444444.png" width="700px" title="source: imgur.com" /></a></p>

<ul>
  <li>what‚Äôs the # of states?
    <ul>
      <li>if we simplify the problem so that we can keep adding x‚Äôs and o‚Äôs even after a player gets 3 in a row</li>
      <li>Each Location on the board has 3 possibilities: empty, X, O</li>
      <li>9 Locations on the Board</li>
      <li>therefore, # states = 3 x 3 ‚Ä¶ x3 = $ 3^9 $</li>
    </ul>
  </li>
</ul>

<script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<div align="center" style="margin: 1em 0;">
<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-5150894678574694" data-ad-slot="9221331439" data-ad-format="auto" data-full-width-responsive="true"></ins>
     </div>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

<h2 id="recap-so-far">Recap so far</h2>

<h3 id="3-important-terms">3 Important Terms</h3>
<p><a href="https://postimg.cc/QB0V4TVw"><img src="https://i.postimg.cc/G21YpPRL/4123141231412.jpg" width="700px" title="source: imgur.com" /></a></p>
<ol>
  <li>Agent: thing that sense the environment, thing we‚Äôre trying to code intelligence/learning into</li>
  <li>Environment: Real World or simulated world that the agent lives in</li>
  <li>State: Different Configurations of the environment that the agent can sense</li>
  <li>Reward
    <ul>
      <li>this is what differentiates RL from other types of ML</li>
      <li>An agent not only tries to maximize its immediate reward, but future rewards as well</li>
      <li>RL algorithms will find novel ways of accomplishing this</li>
      <li>Alphago: learning unique/unpredictable strategies that led to beating a world champion</li>
      <li>Not intuitive to humans, But Rl can figure it out</li>
    </ul>
  </li>
</ol>

<h2 id="unintended-consequenceÏùòÎèÑÏπò-ÏïäÏùÄ-Í≤∞Í≥º">Unintended consequence(ÏùòÎèÑÏπò ÏïäÏùÄ Í≤∞Í≥º)</h2>
<p><a href="https://postimg.cc/1gqs6VwD"><img src="https://i.postimg.cc/zfdBsnf2/41412312412311243.jpg" width="700px" title="source: imgur.com" /></a></p>
<ul>
  <li>possible danger of RL: Unintended consequence</li>
  <li>Commonly repeated ideaL AI could wipe out humanity if it decides that‚Äôs the best thing for us(Ex. Minimize human Deaths)</li>
  <li>AI decided that since # humans grows exponentially, that more people will die in the future, then best to destroy everyone now to minimize dying in the future</li>
  <li>Lower level example : robot trying to solve a maze</li>
  <li>Reasonable goal: solve the maze</li>
  <li>Reward = 1 if solved, reward = 0 if not solved</li>
  <li>Possible solution: move randomly until maze is solved</li>
  <li>is that a good strategy? No!</li>
  <li>we never told the AI that it needs to solve the maze efficiently(we always get the reward in the end)</li>
  <li>what about this: reward of -1 for every step taken</li>
  <li>in order to maximize total reward, must minimize # steps</li>
  <li>Note: reward is always a real number</li>
</ul>

<h2 id="terms">Terms</h2>

<p>Reference
<a href="https://www.udemy.com/cutting-edge-artificial-intelligence/learn/lecture/14650508#overview">Cutting-Edge Deep-Reinforcement Learning</a></p>
:ET