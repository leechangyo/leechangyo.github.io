I"‰e<h1 id="ucb1">UCB1</h1>
<p><a href="https://postimg.cc/R3d6WKJM"><img src="https://i.postimg.cc/hjW930S7/52139182305921.png" width="500px" title="source: imgur.com" /></a></p>

<ul>
  <li>Another Method to Solve Explore-Exploit ( also from A/B Testing Classes)</li>
  <li>Idea: confidence bounds</li>
  <li>Intuitively, we know that sample mean from 10 samples is less accurate than a sample mean from 1000 samples</li>
  <li>Chefnoff Hoeffiding bound:
<a href="https://postimg.cc/YvWgXvG7"><img src="https://i.postimg.cc/T3k93mTK/521252152525215.png" width="200px" title="source: imgur.com" /></a></li>
  <li>Looks complicated, but leads to a simple algorithm
<a href="https://postimg.cc/wyGj8kZG"><img src="https://i.postimg.cc/j2swfgXt/1242141413123.png" width="200px" title="source: imgur.com" /></a></li>
  <li>square(2*ln(N)/N_j) &lt;- â€œChooseâ€ epsilon equal to this upper bound</li>
  <li>N = number of times iâ€™ve played in total, N_j = number of times iâ€™ve played bandit j</li>
  <li>How do we use this formular? Same as optimistic initial values Method</li>
  <li>just be greedy, but with respect to <script type="math/tex">\ln{X}_{UCB-J}</script></li>
  <li>Key: ratio Between ln(N) and $N_j$</li>
  <li>if only $N_j$ is small, then upper bound is high</li>
  <li>if $N_j$ is large, upper bound is small</li>
  <li>ln(N) grow more slowly than N, so eventually all upper bounds will shrink</li>
  <li>by then weâ€™ve collected lots of data, so itâ€™s ok</li>
  <li>so we converge to purely greedy strategy</li>
  <li>Îµ-greedyëŠ” ì¶”ì¸¡ê°’ì´ë‚˜ ë¶ˆí™•ì‹¤ì„±ê³¼ë‘ ê´€ê³„ì—†ì´ ë¬´ì¡°ê±´ ëœë¤í•˜ê²Œ ì‹¤í–‰í•˜ëŠ” ë°˜ë©´ì— ì–´ë–¤ ì•¡ì…˜ì„ í–ˆì„ ë•Œ, ê·¸ ì•¡ì…˜ì€ ë§ì´ í•´ë´¤ìœ¼ë‹ˆ ì–´ëŠì •ë„ ë¶ˆí™•ì‹¤í•  ê²ƒì´ë¼ëŠ” ì „ì¬ë¡œ ë¶ˆí™•ì‹¤ì„±ì„ ê³ ë ¤í•˜ì—¬ ì•¡ì…˜ì„ ì·¨í•œë‹¤.)</li>
  <li>ì¦‰ ì‹œê°„ì´ ì§€ë‚  ìˆ˜ë¡ ln(N)ì˜ ê°’ì€ ì‘ì•„ì§€ëŠ”ë°, ë§ì€ ìƒ˜í”Œë“¤ì´ ìŒ“ì´ë©´ 0ìœ¼ë¡œ ìˆ˜ë ´í•¨ìœ¼ë¡œ ê²°ê³¡ ì ì€ ìƒ˜í”Œì„ ê°€ì§€ê³  ìˆì„ë•Œ ì·¨í•˜ëŠ” ì•¡ì…˜ë“¤ì„ ë³´ì •í•´ì¤€ë‹¤ê³  ë³´ë©´ ëœë‹¤.</li>
</ul>

<blockquote>
  <p>Code</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">Comparing_epsilons</span> <span class="kn">import</span> <span class="n">run_experiment</span> <span class="k">as</span> <span class="n">run_experiment_eps</span>

<span class="k">class</span> <span class="nc">bandit</span><span class="p">:</span>
    <span class="s">"""docstring for ."""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">upper_limit</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">m</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">upper_limit</span>
        <span class="c1">#the mean instance variable is our estimate of the bandit's mean
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="nf">pull</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span>
    <span class="c1"># the pull function which is simulates pulling the bandit's arm
</span>    <span class="c1"># every bandit's reward will be a gassium with unit variant
</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">+=</span><span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mf">1.0</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">+</span> <span class="mf">1.0</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="o">*</span><span class="n">x</span>

    <span class="c1">#Finally, we have the update function which takes an X, which is the latest sample recieved from the bandit
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">ucb</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">nj</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">nj</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="s">'inf'</span><span class="p">)</span> <span class="c1">#infinity
</span>
    <span class="k">return</span> <span class="n">mean</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">/</span> <span class="n">nj</span><span class="p">)</span>
</code></pre></div></div>

<script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<div align="center" style="margin: 1em 0;">
<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-5150894678574694" data-ad-slot="9221331439" data-ad-format="auto" data-full-width-responsive="true"></ins>
     </div>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">run_experiment</span><span class="p">(</span><span class="n">m1</span><span class="p">,</span> <span class="n">m2</span><span class="p">,</span> <span class="n">m3</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="n">bandits</span> <span class="o">=</span> <span class="p">[</span><span class="n">bandit</span><span class="p">(</span><span class="n">m1</span><span class="p">),</span> <span class="n">bandit</span><span class="p">(</span><span class="n">m2</span><span class="p">),</span> <span class="n">bandit</span><span class="p">(</span><span class="n">m3</span><span class="p">)]</span>

    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">([</span><span class="n">ucb</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">b</span><span class="o">.</span><span class="n">N</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">bandits</span><span class="p">])</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">bandits</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">pull</span><span class="p">()</span>
        <span class="n">bandits</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># for the plot
</span>        <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
    <span class="n">cumulative_average</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

  <span class="c1"># for b in bandits:
</span>  <span class="c1">#   print("bandit nj:", b.N)
</span>
  <span class="c1"># plot moving average ctr
</span>    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cumulative_average</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">N</span><span class="p">)</span><span class="o">*</span><span class="n">m1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">N</span><span class="p">)</span><span class="o">*</span><span class="n">m2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">N</span><span class="p">)</span><span class="o">*</span><span class="n">m3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xscale</span><span class="p">(</span><span class="s">'log'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

  <span class="c1"># for b in bandits:
</span>  <span class="c1">#   print(b.mean)
</span>    <span class="k">return</span> <span class="n">cumulative_average</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">'__main__'</span><span class="p">:</span>
    <span class="n">c_1</span> <span class="o">=</span> <span class="n">run_experiment_eps</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">100000</span><span class="p">)</span>
    <span class="n">ucb</span> <span class="o">=</span> <span class="n">run_experiment</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mi">100000</span><span class="p">)</span>

    <span class="c1"># log scale plot
</span>    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">c_1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'eps = 0.1'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ucb</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'ucb1'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xscale</span><span class="p">(</span><span class="s">'log'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="c1"># linear plot
</span>    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">c_1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'eps = 0.1'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ucb</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'ucb1'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<h1 id="bayesian-method">Bayesian Method</h1>
<p><a href="https://postimg.cc/QKtZ0VDD"><img src="https://i.postimg.cc/Bb5ZZ1wj/4124124141.png" width="500px" title="source: imgur.com" /></a></p>
<ul>
  <li>thompson sampling(ê° ë³´ìƒ(reward) ë¶„í¬ì˜ íŒŒë¼ë¯¸í„° í™•ë¥  ë³€ìˆ˜ë¥¼ ë³´ê³  ì´ íŒŒë¼ë¯¸í„°ì˜ ë¶„í¬ë¡œ ë¶€í„° ë¬´ì‘ìœ„ë¡œ ì¶”ì¶œí•˜ì—¬ í•´ë‹¹ ê°’ì— ëŒ€í•œ Reward ê¸°ëŒ€ê°’ì´ ê°€ì¥ ë†’ì€ ê¸°ê³„ë¥¼ ì„ íƒí•œë‹¤. ê·¸ë¦¬ê³  ë‚˜ì„œ Bayesian ì •ë¦¬ë¥¼ ì´ìš©í•˜ì—¬ ê¸°ê³„ì— ëŒ€í•œ íŒŒë¼ë¯¸í„° ë¶„í¬ë¥¼ ì—…ë°ì´íŠ¸ í•œë‹¤. Iterationì„ í•˜ì—¬ ì ì  ë†’ì•„ì§€ëŠ” ë³´ìƒì˜ í‰ê· ì˜ ê¸°ê³„ë¥¼ ì„ íƒí•˜ê²Œ ëœë‹¤.)</li>
  <li>Letâ€™s think about confidence intervals again</li>
  <li>we know Intuitively that sample mean from 10 samples is less accurate than sample mean from 1000 samples</li>
  <li>Central Limit Theorem says that sample mean is <strong>approximately Gaussian</strong></li>
  <li>Any Function of RVs is a RV(random Variable)
<a href="https://postimg.cc/p9KtGgn0"><img src="https://i.postimg.cc/R0DVFmCz/141414141412314.png" width="200px" title="source: imgur.com" /></a></li>
  <li>Bayesian paradigm takes this a step further</li>
  <li>what if <em>Î¼</em> is Also a RV?</li>
  <li>Data is fixed; parameters are random</li>
  <li>we want to find the distribution of the parameter(å…¥æ•°) given the data</li>
  <li>should be more accurate than if did not have the data</li>
  <li>we call this the Posterior
<a href="https://postimg.cc/WD4s39DS"><img src="https://i.postimg.cc/MG7H9Nzk/4112414123131.png" width="200px" title="source: imgur.com" /></a></li>
  <li>Flip the Posterior to find it in terms of likelihood and prior
<a href="https://postimg.cc/14R3XcT8"><img src="https://i.postimg.cc/v8fgP0tt/4124141241312.png" width="500px" title="source: imgur.com" /></a></li>
  <li>Likelihood(ì—°ì† ì‚¬ê±´ì—ì„œëŠ” êµ¬ê°„ì— ëŒ€í•œ ì¶”ì •ì€ ê°€ëŠ¥í•˜ì§€ë§Œ(PDF(Probability Density Function)), íŠ¹ì •ì‚¬ê±´ì— ëŒ€í•œ ì¶”ì •ì´ ë¶ˆê°€ëŠ¥í• ë•Œ PDFì—ì„œ yê°’ì„ ì´ìš©í•´ì„œ Pê°’ì„ êµ¬í•˜ê² ë‹¤ë¼ëŠ” ê²ƒì´ë‹¤. ì¦‰ 0~100ê¹Œì§€ ìˆëŠ” ë³€ìˆ˜ì¤‘ì—ì„œ 30ì„ ë½‘ì„ í™•ë¥ ì€ 0ì´ì§€ë§Œ likelihoodë¡œ ë³´ì•˜ì„ë•Œì—ëŠ” 0.4ì¸ ê²ƒì´ë‹¤. ì¦‰ ì„¸ë²ˆ ì—°ì†ìœ¼ë¡œ ë½‘ì•˜ì„ë–„ 2,49,20 ì´ ë‚˜ì˜¬ í™•ë£”ì€ 0 X 0 X 0ìœ¼ë¡œ 0ì´ì§€ë§Œ, Likelihoodì—ì„œëŠ” 0.4 x 0.2 x 0.01 = 0.008 ì´ë‹¤.</li>
  <li>Disadvantage of Bayesian method: we must choose the prior
    <ul>
      <li>Non-negligible effect on Posterior
<a href="https://postimg.cc/m13n7HhV"><img src="https://i.postimg.cc/ZnXhtPmk/41414141.png" width="500px" title="source: imgur.com" /></a></li>
    </ul>
  </li>
  <li>Problem: Integral is usually intractable(å¾ˆéš¾å¤„ç†çš„), we need â€œtricksâ€ to solve this(ë§Œì•½ Bayesianìœ¼ë¡œ Posteriorë¥¼ ê³„ì‚°í•œë‹¤ê³  í•  ë•Œ, ê° í•­ëª©ì´ ì¼ë°˜ì ì¸ ë¶„í¬ë¥¼ ë”°ë¥´ì§€ ì•ŠëŠ—ë‹¤ê³  í•œë‹¤ë©´(ì¦‰ ë“¤ì‘¥ ë‚ ì‘¥) ë„ì¶œí•˜ëŠ” ë°©ì‹ì´ ë§¤ìš° ì–´ë µê¸° ë•Œë¬¸ì— Trickì´ í•„ìš”. ì˜ˆë¡œ ì…ìˆ ì— ë¹¨ê°„ìƒ‰ì´ ë­ì—ˆì„ë•Œ ê¹€ì¹˜ë¥¼ ë¨¹ì—ˆëŠ”ì§€ ê³ ì¶”ì¥ì„ ë¨¹ì—ˆëŠ”ì§€ ì˜ˆì¸¡í•  ìˆ˜ ìˆëŠ” ê²ƒì´ë‹¤.)</li>
  <li>special(likelihood,prior) pairs where we can easily solve this</li>
  <li>called conjugate priors(Likelihoodê°€ íŠ¹ì • ë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤ê³  í•  ë•Œ, Priorì™€ Posteriorê°€ ë™ì¼í•œ ë¶„í¬ë©´ ê³„ì‚°ì´ ë¹¨ë¼ì§„ë‹¤.)</li>
  <li>Click-Through rate are like coin tosses; likelihood is bernoulli</li>
  <li>look up on wikipedia: what is <a href="https://rpubs.com/sitaramgautam/145048">conjugate prior</a> for bernoulli likelihood? <em>Beta</em> (Posteriorê°€ Likelihoodì˜ íŠ¹ì •ë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤.)</li>
  <li>make sense; beta is in [0,1]</li>
  <li>Likelihood:
<a href="https://postimg.cc/gXBgbHQx"><img src="https://i.postimg.cc/HnTR5St9/41414141414141.png" width="400px" title="source: imgur.com" /></a></li>
  <li>Prior:
<a href="https://postimg.cc/MM8QMMB9"><img src="https://i.postimg.cc/PxCz715n/51511.png" width="400px" title="source: imgur.com" /></a></li>
  <li>combine likelihood and prior to solve for posterior:
<a href="https://postimg.cc/tZ5N9tc3"><img src="https://i.postimg.cc/7hvsMKMW/595959.png" width="400px" title="source: imgur.com" /></a></li>
  <li>B(a,b) can be dropped (abosrbed into Normalization constant)</li>
  <li>Key: posterior takes the form of a beta distribution
<a href="https://postimg.cc/1gN9xvfd"><img src="https://i.postimg.cc/pdsyF7xP/4444124.png" width="400px" title="source: imgur.com" /></a></li>
  <li>New a,b :  aâ€™ = a + #1â€™s , bâ€™ = b + #0â€™s
<script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script></li>
</ul>
<div align="center" style="margin: 1em 0;">
<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-5150894678574694" data-ad-slot="9221331439" data-ad-format="auto" data-full-width-responsive="true"></ins>
     </div>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

<ul>
  <li>script from A/B testing class: demonstrate to ourself how posterior is updated as we collect clicks/impressions(or heads/tails)</li>
  <li>we start with the priors $a_0$=1, $b_0$=0 (uniform distribution)</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># From the course: Bayesin Machine Learning in Python: A/B Testing
# https://deeplearningcourses.com/c/bayesian-machine-learning-in-python-ab-testing
# https://www.udemy.com/bayesian-machine-learning-in-python-ab-testing
</span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span><span class="p">,</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">builtins</span> <span class="kn">import</span> <span class="nb">range</span>
<span class="c1"># Note: you may need to update your version of future
# sudo pip install -U future
</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">beta</span>

<span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">trial</span><span class="p">,</span> <span class="n">ctr</span><span class="p">):</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
  <span class="n">mean</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Distributions after </span><span class="si">%</span><span class="s">s trials, true rate = </span><span class="si">%.1</span><span class="s">f, mean = </span><span class="si">%.2</span><span class="s">f"</span> <span class="o">%</span> <span class="p">(</span><span class="n">trial</span><span class="p">,</span> <span class="n">ctr</span><span class="p">,</span> <span class="n">mean</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">true_ctr</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span> <span class="c1"># beta parameters
</span><span class="n">show</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">700</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">1500</span><span class="p">]</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1501</span><span class="p">):</span>
  <span class="n">coin_toss_result</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">true_ctr</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">coin_toss_result</span><span class="p">:</span>
    <span class="n">a</span> <span class="o">+=</span> <span class="mi">1</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">b</span> <span class="o">+=</span> <span class="mi">1</span>

  <span class="k">if</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">show</span><span class="p">:</span>
    <span class="n">plot</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">true_ctr</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li>Pattern: distribution of CTR gets skinnier/taller as we collect Data</li>
  <li>Because weâ€™re becoming more confident in that estimate/variance decreases</li>
  <li>Natural way to represent confidence bounds</li>
  <li>is an instance of online learning</li>
  <li>distribution becomes more precise after every coin toss, not just after we collect all the data</li>
  <li>All the methods weâ€™ll learn later (iterative update)</li>
</ul>

<h1 id="ì°¸ì¡°-gaussian-likelihoodprior">ì°¸ì¡°) Gaussian Likelihood/Prior</h1>

<ul>
  <li>data likelihood is Gaussian</li>
  <li>we try to find Î¼ only (also Gaussian)
<a href="https://postimg.cc/rDYfRkqD"><img src="https://i.postimg.cc/6QBgSWSf/1241.png" width="400px" title="source: imgur.com" /></a></li>
  <li>Work with precisions(inverse variance)
    <ul>
      <li>Easier</li>
    </ul>
  </li>
  <li>weâ€™re looking for the update equations for m and Î»</li>
  <li>Gaussian Posterior
<a href="https://postimg.cc/yJL381KG"><img src="https://i.postimg.cc/RFB7GhDv/400103.png" width="400px" title="source: imgur.com" /></a></li>
</ul>
:ET