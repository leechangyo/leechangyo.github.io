I"”<h1 id="what-is-reinforcement-learning">What is Reinforcement Learning?</h1>

<p><a href="https://postimg.cc/qNRLDkZb"><img src="https://i.postimg.cc/130jtX0Q/14512412123124123.png" width="700px" title="source: imgur.com" /></a></p>

<ul>
  <li>Humans/ AIs alike never sense the entire world/universe at once</li>
  <li>We have sensors which feed signals to our brain from the environment</li>
  <li>We don‚Äôt even know everything that‚Äôs going on in a room</li>
  <li>Thus the Sensors limit the amount of information we get</li>
  <li>The measurements we get from these sensors(e.g. sight, sound touch) make up a ‚Äústate‚Äù</li>
  <li>we‚Äôll only discuss finite state spaces</li>
  <li>state spaces with an infinite number of states are possible too</li>
</ul>

<p><a href="https://postimg.cc/y3jG9Lkk"><img src="https://i.postimg.cc/hhRRkwnb/444444.png" width="700px" title="source: imgur.com" /></a></p>

<ul>
  <li>what‚Äôs the # of states?
    <ul>
      <li>if we simplify the problem so that we can keep adding x‚Äôs and o‚Äôs even after a player gets 3 in a row</li>
      <li>Each Location on the board has 3 possibilities: empty, X, O</li>
      <li>9 Locations on the Board</li>
      <li>therefore, # states = 3 x 3 ‚Ä¶ x3 = $ 3^9 $</li>
    </ul>
  </li>
</ul>

<script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<div align="center" style="margin: 1em 0;">
<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-5150894678574694" data-ad-slot="9221331439" data-ad-format="auto" data-full-width-responsive="true"></ins>
     </div>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

<h1 id="recap-so-far">Recap so far</h1>

<h2 id="3-important-terms">3 Important Terms</h2>
<p><a href="https://postimg.cc/QB0V4TVw"><img src="https://i.postimg.cc/G21YpPRL/4123141231412.jpg" width="700px" title="source: imgur.com" /></a></p>
<ol>
  <li>Agent: thing that sense the environment, thing we‚Äôre trying to code intelligence/learning into</li>
  <li>Environment: Real World or simulated world that the agent lives in</li>
  <li>State: Different Configurations of the environment that the agent can sense</li>
  <li>Reward
    <ul>
      <li>this is what differentiates RL from other types of ML</li>
      <li>An agent not only tries to maximize its immediate reward, but future rewards as well</li>
      <li>RL algorithms will find novel ways of accomplishing this</li>
      <li>Alphago: learning unique/unpredictable strategies that led to beating a world champion</li>
      <li>Not intuitive to humans, But Rl can figure it out</li>
    </ul>
  </li>
</ol>

<h2 id="unintended-consequenceÏùòÎèÑÏπò-ÏïäÏùÄ-Í≤∞Í≥º">Unintended consequence(ÏùòÎèÑÏπò ÏïäÏùÄ Í≤∞Í≥º)</h2>
<p><a href="https://postimg.cc/1gqs6VwD"><img src="https://i.postimg.cc/zfdBsnf2/41412312412311243.jpg" width="700px" title="source: imgur.com" /></a></p>
<ul>
  <li>possible danger of RL: Unintended consequence</li>
  <li>Commonly repeated ideaL AI could wipe out humanity if it decides that‚Äôs the best thing for us(Ex. Minimize human Deaths)</li>
  <li>AI decided that since # humans grows exponentially, that more people will die in the future, then best to destroy everyone now to minimize dying in the future</li>
  <li>Lower level example : robot trying to solve a maze</li>
  <li>Reasonable goal: solve the maze</li>
  <li>Reward = 1 if solved, reward = 0 if not solved</li>
  <li>Possible solution: move randomly until maze is solved</li>
  <li>is that a good strategy? No!</li>
  <li>we never told the AI that it needs to solve the maze efficiently(we always get the reward in the end)</li>
  <li>what about this: reward of -1 for every step taken</li>
  <li>in order to maximize total reward, must minimize # steps</li>
  <li>Note: reward is always a real number</li>
</ul>

<h2 id="terms">Terms</h2>
<script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<div align="center" style="margin: 1em 0;">
<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-5150894678574694" data-ad-slot="9221331439" data-ad-format="auto" data-full-width-responsive="true"></ins>
     </div>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

<p>So far: agent, environment, state, reward</p>

<p>Next : actions</p>

<p><strong>Actions</strong> are what an agent does in its environment. (Ex. agent = a 2-D video game character. Action = {up, down, left, right, jump}). we look at finite sets of actions only.</p>

<h2 id="sar-triples">Sar Triples</h2>
<p><a href="https://postimg.cc/87WsrcSq"><img src="https://i.postimg.cc/XY15mBD7/14123124213.png" width="700px" title="source: imgur.com" /></a></p>

<p>We often think about <strong>(state, action, reward)</strong> as a Triple
Notation : (S,A,R)</p>

<h2 id="timing">Timing</h2>
<ul>
  <li>Timing is Important in RL</li>
  <li>Every game is a Sequence of states, actions, rewards.</li>
  <li>Convention(Í¥ÄÏäµ): Start in state S(t), take action A(t), receive a reward of R(t+1)</li>
  <li>Reward always result from (s,a) we took at previous time</li>
  <li>S(t), A(t) also brings us to a new state, S(t+1)</li>
  <li>this also makes a triple: [S(t), A(t), S(t+1)]</li>
  <li>Also Denoted as : (s,a,s‚Äô)</li>
</ul>

<h1 id="summary">Summary</h1>
<ul>
  <li>Program the agent to be intelligent</li>
  <li>Agent interacts with its environment by being in a state, taking action based on that state, which brings it to a new state</li>
  <li>Environment gives the agent a reward, can be +ve or -ve(but must be real number)</li>
  <li>Reward is received in next state</li>
</ul>

<p>Reference
<a href="https://www.udemy.com/course/artificial-intelligence-reinforcement-learning-in-python/">Artificial Intelligence Reinforcement Learning</a>
<a href="https://www.udemy.com/deep-reinforcement-learning-in-python/">Advance AI : Deep-Reinforcement Learning</a>
<a href="https://www.udemy.com/cutting-edge-artificial-intelligence/learn/lecture/14650508#overview">Cutting-Edge Deep-Reinforcement Learning</a></p>
:ET