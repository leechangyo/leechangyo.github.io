I"N<h1 id="optimization-in-signal-and-image-processing">Optimization in Signal and Image processing</h1>

<h2 id="model-arising-in-compressive-sensing-and-imaging-sciences">Model arising in compressive sensing and imaging sciences</h2>

<ul>
  <li>Separable(å¯åˆ†å¼€çš„) Structures of problems</li>
</ul>

<p><a href="https://postimg.cc/zL2TZB2S"><img src="https://i.postimg.cc/vBbhnxWj/Capture.png" width="700px" title="source: imgur.com" /><a></a></a></p>

<ul>
  <li>Convexity and easy subproblems(å­é—®é¢˜).</li>
  <li>Often involving large, nonsmooth convex functions with separable structure.</li>
  <li><a href="https://math.stackexchange.com/questions/2201384/what-is-the-definition-of-a-first-order-method">First-order method</a> can be very slow for producing high accuracy solutions, but also share many advantages:
    <ul>
      <li>Non-differentiability</li>
      <li>Use minimal information, e.g.,(f;âˆ‡f)</li>
      <li>Often lead to very simple and â€œcheapâ€ iterative schemes</li>
      <li><strong>Complexity/iteration mildly dependent (e.g., linear) in problemâ€™s dimension</strong></li>
      <li>Suitable when high accuracy is not crucial [in many large scale applications, the data is anyway corrupted or known only roughly</li>
    </ul>
  </li>
</ul>

<h2 id="example-compressive-sensingkernel-ê°™ì€-ê°œë…">Example: compressive sensing(Kernel ê°™ì€ ê°œë…)</h2>
<ul>
  <li>Goal: Recover sparse signal from very few linear measurements.
<a href="https://postimg.cc/gX55JGj3"><img src="https://i.postimg.cc/WzbP53PY/Capture.png" width="700px" title="source: imgur.com" /><a></a></a></li>
  <li>Basis pursuit model:
<a href="https://postimg.cc/gLFDQjrt"><img src="https://i.postimg.cc/3NWcyDhh/Capture.png" width="700px" title="source: imgur.com" /><a></a></a></li>
</ul>

<h2 id="compressive-sensing">Compressive Sensing</h2>
<ul>
  <li>Find the sparest solution
    <ul>
      <li>Given n=256, m=128.
        <ul>
          <li>n is original signal</li>
          <li>m is output value</li>
        </ul>
      </li>
      <li>A = randn(m,n); u = sprandn(n, 1, 0.1); b = A*u;
<a href="https://postimg.cc/pmT6D9jK"><img src="https://i.postimg.cc/3xCQQmJf/Capture.png" width="700px" title="source: imgur.com" /><a></a></a></li>
    </ul>
  </li>
</ul>

<h2 id="sparseí”íˆ-ë„“ì€-ì§€ì—­ì—-ë¶„í¬ëœ-ì •ë„ê°€-ë“œë¬¸-ë°€ë„ê°€-í¬ë°•í•œ-recovery-models">Sparse((í”íˆ ë„“ì€ ì§€ì—­ì— ë¶„í¬ëœ ì •ë„ê°€) ë“œë¬¸, (ë°€ë„ê°€) í¬ë°•í•œ) recovery models</h2>
<p><a href="https://postimg.cc/YhjPFGYY"><img src="https://i.postimg.cc/wTkYSDBf/Capture.png" width="700px" title="source: imgur.com" /><a></a></a></p>

<h2 id="sparsityí”íˆ-ë„“ì€-ì§€ì—­ì—-ë¶„í¬ëœ-ì •ë„ê°€-ë“œë¬¸-ë°€ë„ê°€-í¬ë°•í•œ-under-a-basis">Sparsity((í”íˆ ë„“ì€ ì§€ì—­ì— ë¶„í¬ëœ ì •ë„ê°€) ë“œë¬¸, (ë°€ë„ê°€) í¬ë°•í•œ) under a basis</h2>
<ul>
  <li>Given a reprenting basis or dictionary, we want to recover a signal which is sparse under this basis.</li>
  <li>Two types of models:</li>
</ul>

<p><a href="https://postimg.cc/1gGk58N6"><img src="https://i.postimg.cc/HLRdz5YS/Capture.png" width="700px" title="source: imgur.com" /><a></a></a></p>

<ul>
  <li>Commonly used dictionaries include both analytic and trained ones.
    <ul>
      <li>analytic bases: Id, DCT, wavelets, curvelets, gabor, etc., also their combinations; they have analytic properties, often easy to compute (for example, multiplying a vector takes O(n log n) instead of O($n^2$))
        <h1 id="reference">Reference</h1>
      </li>
    </ul>
  </li>
</ul>

<p><a href="https://web.stanford.edu/class/ee364a/lectures.html"> Optimization method - Standford University </a></p>
:ET