I"<h1 id="1-native本地的-solution-to-tic-tac-toe">1. Native(本地的) Solution to Tic-Tac-Toe</h1>
<p><a href="https://postimg.cc/nsyfqDpQ"><img src="https://i.postimg.cc/9MMX5dk1/512124123124.png" width="700px" title="source: imgur.com" /></a></p>
<ul>
  <li>Small set of rules to ensure we never lose</li>
  <li>we enumerate(列举) the rule of Tic-Tac-Toe. but we won’t. still consider what they might be( Ex, if board is empty and it’s our turn, place our piece in the center or corner)(Ex2, if opponent has 2 piece in a row, block the 3rd postion so they don’t win)(Ex3, if we have 2 piece in a row, add a 3rd so we can win the game)</li>
  <li>Code would like this
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
<span class="p">{</span><span class="o">...</span><span class="p">}</span>
<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="o">...</span><span class="p">):</span>
<span class="p">{</span><span class="o">...</span><span class="p">}</span>
<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="o">...</span><span class="p">):</span>
<span class="p">{</span><span class="o">...</span><span class="p">}</span>
</code></pre></div>    </div>
  </li>
  <li>Goes against the whole idea of ML</li>
  <li>We want one algorithm that can generalize(概括) to many problem(E.g neural network can classify pictures of animals, can also classify music)</li>
  <li>An agent made up of it statements will never be able to do anything other than just play tic-tac-toe(Agent only doing tic-tac-toe)</li>
  <li>Important: we have a model for how the game works. we know everything about tic-tac-toe</li>
  <li>We Know what state yields the highest reward(any state where we have 3 pieces in a row)</li>
  <li>i.e. by doing some action, we know the next state is given the current state(predict)</li>
  <li>Seems Trivial(不重要的), but not always the case</li>
</ul>

<h2 id="model">Model</h2>
<p><a href="https://postimg.cc/qh2qK0V4"><img src="https://i.postimg.cc/xC4zWT6J/512312412312431.png" width="700px" title="source: imgur.com" /></a></p>
<ul>
  <li>the idea of having a model of the environment will come into play later.</li>
  <li>some algorithms we’ll learn will require us to have a model, like tic-tac-toe</li>
  <li>other algorithms won’t require us to know anything, we’ll just explore the world and consume information as we go along</li>
</ul>

<h1 id="2-components-of-a-rl-systems">2. Components of a RL systems</h1>
<p><a href="https://postimg.cc/rd9dKMSW"><img src="https://i.postimg.cc/zfsT2fvd/51212413.png" width="700px" title="source: imgur.com" /></a></p>

<h2 id="state">State</h2>
<ul>
  <li>Note that State involves only what the agent can sense, not everything about the environment(Ex. Vacuum robot in Australia won’t be affected by something happening in india)</li>
</ul>

<h2 id="actions-and-rewards">Actions and Rewards</h2>
<ul>
  <li>Actions：
    <ul>
      <li>Things Agent can do that will affect its state. in tic-tac-toe, that’s placing a piece on the board(like Player)</li>
      <li>Preforming an action always brings us to the next state, which also comes with a possible reward.</li>
    </ul>
  </li>
  <li>Rewards：
    <ul>
      <li>Rewards tell us “how good” our actions was, not whether it was a correct/incorrect action</li>
      <li>doesn’t tell us the best/Worst action</li>
      <li>it’s just a number</li>
      <li>rewards we’ve gotten over the course of our existence doesn’t necessarily represent possible rewards we could get in the future（E.g Search a bad part of state space, hit local max of 10 pts, but global max is 1000pts)</li>
      <li>Agent Doesn’t know that.</li>
      <li>Much like life as an animal/Human Being</li>
      <li>Rewards are only meaningful relative to each other</li>
    </ul>
  </li>
</ul>

<h2 id="funny-notation">Funny Notation</h2>
<ul>
  <li>S(t),A(t) -&gt; R(t+1),A(t+1)</li>
  <li>sometimes represented as the 4-tuples: (s,a,r,s’)</li>
  <li>oddly, the “prime” symbol doesn’t strictly mean “at the t+1”</li>
  <li>Instead:
    <ul>
      <li>s’= state we go to when doing “a” from state “s”</li>
      <li>r = reward get when we do “a” while in state “s”
<script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script></li>
    </ul>
  </li>
</ul>
<div align="center" style="margin: 1em 0;">
<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-5150894678574694" data-ad-slot="9221331439" data-ad-format="auto" data-full-width-responsive="true"></ins>
     </div>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

<h2 id="episode">Episode</h2>
<ul>
  <li>Episode represents one run of the game(Ex. start tic-tac-toe with empty board)</li>
  <li>As soon as one player gets 3 pieces in a row, that’s the end of the episode</li>
  <li>our RL agent will learn across many episodes(Ex. after playing 1000,10000 or 100000 episodes, we can possibly have trained an intelligent agent)</li>
  <li>. # episodes we use to train is a hyperparameter</li>
  <li>playing the game tic-tac-toe is an <strong>episode task</strong> because we play it again and again</li>
  <li>Different from a <strong>continuous task</strong> which never ends</li>
  <li>when is the end of an episode?</li>
  <li>Certain states in the state space tell us when the episode is over.</li>
  <li>There are states from which more action can be taken</li>
  <li>They are called <strong>Terminal States</strong></li>
  <li>For Tic-Tac_toe:
    <ul>
      <li>one player gets 3 in a row</li>
      <li>Board is full(draw)</li>
    </ul>
  </li>
</ul>

<h1 id="3-other-gamescart-poleinverted-pendulumgroundhog-day">3. Other Games(Cart-pole/inverted pendulum/Groundhog Day)</h1>
<p><a href="https://postimg.cc/V0X2s4hk"><img src="https://i.postimg.cc/7hR4VWM0/215321342315234.png" width="500px" title="source: imgur.com" /></a></p>
<ul>
  <li>Control systems: Inverted pendulum</li>
  <li>RL : Cart-Pole</li>
  <li>Unstable system</li>
  <li>Episode starts which pole vertical, soon falls</li>
  <li>Agent: Move to Keep the pole within certain angle.</li>
  <li>Terminal : any angle past the point of no return</li>
  <li>Angle requires continuous state space</li>
  <li>infinite number of states
<a href="https://postimg.cc/ftVfvLj4"><img src="https://i.postimg.cc/qRLD46N7/5123214123.png" width="500px" title="source: imgur.com" /></a></li>
</ul>
:ET