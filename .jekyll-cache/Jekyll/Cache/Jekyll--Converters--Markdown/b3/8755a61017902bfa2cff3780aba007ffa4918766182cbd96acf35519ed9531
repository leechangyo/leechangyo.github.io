I"È<h1 id="modifications-for-cartpole">Modifications for CartPole</h1>

<ul>
  <li>Can we use the RBF Network + Q learning script with CartPole?</li>
  <li>Yes But with some modifications</li>
</ul>

<h2 id="sgdregressor">SGDRegressor</h2>
<ul>
  <li>we are going to build our own</li>
  <li>Practice building a linear gradient descent model</li>
  <li>We‚Äôll use the sampe API as scikit learn‚Äôs SGDRegressor</li>
  <li>Can‚Äôt use Optimistic initial value</li>
</ul>

<h2 id="rbf-example">RBF Example</h2>

<ul>
  <li>for mountain car, we sampled from the state space to get exemplars</li>
  <li>mountain car state space is bounded in a small region</li>
  <li>Cartpole state space is not</li>
  <li>Unfortunately the sample() method samples uniformly from all possible values, not proportional to how likely they are</li>
  <li>therefore, these would be poor exemplars</li>
  <li>instead, just ‚Äúguess‚Äù a plausible range( or collect data to find it)</li>
  <li>use different sacles too</li>
</ul>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>No &lt;= observation_examples = np.array([env.observation_space.sample() for in range(20000)])
YES &lt;= observation_examples = np.random.random((2000,4))*2 -2
</code></pre></div></div>

<blockquote>
  <p>Import Library
Reference:</p>
</blockquote>

<p><a href="https://www.udemy.com/course/artificial-intelligence-reinforcement-learning-in-python/">Artificial Intelligence Reinforcement Learning</a></p>

<p><a href="https://www.udemy.com/deep-reinforcement-learning-in-python/">Advance AI : Deep-Reinforcement Learning</a></p>

<p><a href="https://www.udemy.com/cutting-edge-artificial-intelligence/learn/lecture/14650508#overview">Cutting-Edge Deep-Reinforcement Learning</a></p>
:ET